{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import splitfolders\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nimport cv2\nfrom skimage.color import lab2rgb, rgb2lab, rgb2gray\nfrom skimage import io\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import Image, display\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport torchvision.models as models\nfrom torchvision import datasets, transforms\n\nimport os, shutil, time\n\ndevice = \"cpu\"\nif torch.cuda.is_available():             \n    device = \"cuda\"\n    \nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-17T11:30:18.262198Z","iopub.execute_input":"2021-12-17T11:30:18.262524Z","iopub.status.idle":"2021-12-17T11:30:21.563124Z","shell.execute_reply.started":"2021-12-17T11:30:18.262488Z","shell.execute_reply":"2021-12-17T11:30:21.562420Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"splitfolders.ratio('../input/', output=\"../output/\", seed=1337, ratio=(.8, 0.1,0.1)) ","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:30:21.564432Z","iopub.execute_input":"2021-12-17T11:30:21.564983Z","iopub.status.idle":"2021-12-17T11:31:01.561790Z","shell.execute_reply.started":"2021-12-17T11:30:21.564953Z","shell.execute_reply":"2021-12-17T11:31:01.561248Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"##!pip install split-folders","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:01.564578Z","iopub.execute_input":"2021-12-17T11:31:01.564945Z","iopub.status.idle":"2021-12-17T11:31:01.569271Z","shell.execute_reply.started":"2021-12-17T11:31:01.564901Z","shell.execute_reply":"2021-12-17T11:31:01.568400Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"list_files = os.listdir('../output')\nlist_train_files = os.listdir('../output/train/landscape-pictures/')\nlist_val_files = os.listdir('../output/val/landscape-pictures/')\nlist_test_files = os.listdir('../output/test/landscape-pictures/')\n\nprint(len(list_train_files))\nprint(len(list_val_files))\nprint(len(list_test_files))","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:01.571690Z","iopub.execute_input":"2021-12-17T11:31:01.571902Z","iopub.status.idle":"2021-12-17T11:31:01.672398Z","shell.execute_reply.started":"2021-12-17T11:31:01.571877Z","shell.execute_reply":"2021-12-17T11:31:01.671559Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class LoadData(datasets.ImageFolder):\n    def __getitem__(self, index):\n        path, target = self.imgs[index]\n        img = self.loader(path)\n        \n        if self.transform is not None:\n            img_original = self.transform(img)\n            img_original = np.asarray(img_original)\n            img_lab = rgb2lab(img_original)\n            img_lab = (img_lab + 128) / 255\n            img_ab = img_lab[:, :, 1:3]\n            img_ab = torch.from_numpy(img_ab.transpose((2, 0, 1))).float()\n            img_original = rgb2gray(img_original)\n            img_original = torch.from_numpy(img_original).unsqueeze(0).float()\n\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n            \n        return img_original, img_ab, target\n","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:01.674250Z","iopub.execute_input":"2021-12-17T11:31:01.674605Z","iopub.status.idle":"2021-12-17T11:31:01.684389Z","shell.execute_reply.started":"2021-12-17T11:31:01.674573Z","shell.execute_reply":"2021-12-17T11:31:01.683520Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Training\ntrain_transforms = transforms.Compose([transforms.Resize((224,224))])\ntrain_imagefolder = LoadData('../output/train/', train_transforms)\ntrain_loader = torch.utils.data.DataLoader(train_imagefolder, batch_size=64, shuffle=True)\n\n# Validation \nval_transforms = transforms.Compose([transforms.Resize((224,224))])\nval_imagefolder = LoadData('../output/val/' , val_transforms)\nval_loader = torch.utils.data.DataLoader(val_imagefolder, batch_size=64, shuffle=False)\n\n# test\ntest_transforms = transforms.Compose([transforms.Resize((224,224))])\ntest_imagefolder = LoadData('../output/test/' , test_transforms)\ntest_loader = torch.utils.data.DataLoader(test_imagefolder, batch_size=64, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:01.685787Z","iopub.execute_input":"2021-12-17T11:31:01.686012Z","iopub.status.idle":"2021-12-17T11:31:01.722224Z","shell.execute_reply.started":"2021-12-17T11:31:01.685960Z","shell.execute_reply":"2021-12-17T11:31:01.721395Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for i, (input_gray, input_ab, target) in enumerate(val_loader):\n  print(input_gray.shape)\n  print()\n  print(input_ab.shape)\n  print()\n  print(target.shape)\n  break","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:01.723514Z","iopub.execute_input":"2021-12-17T11:31:01.723725Z","iopub.status.idle":"2021-12-17T11:31:03.815651Z","shell.execute_reply.started":"2021-12-17T11:31:01.723701Z","shell.execute_reply":"2021-12-17T11:31:03.814782Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n  def __init__(self):\n    super(Model, self).__init__()\n\n    ## First half: ResNet\n    resnet = models.resnet18(num_classes=365) \n    # Change first conv layer to accept single-channel (grayscale) input\n    resnet.conv1.weight = nn.Parameter(resnet.conv1.weight.sum(dim=1).unsqueeze(1)) \n    # Extract midlevel features from ResNet-gray\n    self.midlevel_resnet = nn.Sequential(*list(resnet.children())[0:6])\n\n\n    ## Second half: Upsampling\n    self.decoder = nn.Sequential(     \n      nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(128),\n      nn.ReLU(),\n      nn.Upsample(scale_factor=2),\n      nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(64),\n      nn.ReLU(),\n      nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(64),\n      nn.ReLU(),\n      nn.Upsample(scale_factor=2),\n      nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(32),\n      nn.ReLU(),\n      nn.Conv2d(32, 2, kernel_size=3, stride=1, padding=1),\n      nn.Upsample(scale_factor=2),\n      \n    )\n\n  def forward(self, input):\n\n    # Pass input through ResNet-gray to extract features\n    midlevel_features = self.midlevel_resnet(input)\n\n\n    # Upsample to get colors\n    output = self.decoder(midlevel_features)\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:03.816981Z","iopub.execute_input":"2021-12-17T11:31:03.817322Z","iopub.status.idle":"2021-12-17T11:31:03.828266Z","shell.execute_reply.started":"2021-12-17T11:31:03.817280Z","shell.execute_reply":"2021-12-17T11:31:03.827047Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = Model()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:03.829285Z","iopub.execute_input":"2021-12-17T11:31:03.829523Z","iopub.status.idle":"2021-12-17T11:31:04.060023Z","shell.execute_reply.started":"2021-12-17T11:31:03.829486Z","shell.execute_reply":"2021-12-17T11:31:04.059247Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.MSELoss()\nloss_func.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay =0.0)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:04.061156Z","iopub.execute_input":"2021-12-17T11:31:04.061464Z","iopub.status.idle":"2021-12-17T11:31:04.066372Z","shell.execute_reply.started":"2021-12-17T11:31:04.061433Z","shell.execute_reply":"2021-12-17T11:31:04.065512Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, data_loader, loss_func, optimizer, device):\n    model= model.train()\n    losses = []\n    total_batches = len(data_loader)\n    i=1\n    \n    start = time.time()\n    \n    for i, (input_gray, input_ab, target) in enumerate(data_loader):\n        input_gray = input_gray.to(device)\n        input_ab = input_ab.to(device)\n        target = target.to(device)\n        \n        # Run forward pass\n        output_ab = model(input_gray) \n        loss = loss_func(output_ab, input_ab) \n        losses.append(loss.item())\n        \n        \n        if ((i+1)%10) == 0:\n            print(\"Batch {}/{} Train Loss {:.4f} \".format(i+1, total_batches, loss.item()))\n        i += 1\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n        optimizer.step()\n        optimizer.zero_grad()\n    \n    end =  time.time()\n    epoch_time = end-start\n    return np.mean(losses),epoch_time","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:04.067823Z","iopub.execute_input":"2021-12-17T11:31:04.068031Z","iopub.status.idle":"2021-12-17T11:31:04.079714Z","shell.execute_reply.started":"2021-12-17T11:31:04.068008Z","shell.execute_reply":"2021-12-17T11:31:04.078918Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, loss_func,device):\n    model = model.eval()\n    \n    losses = []\n    eval_predictions = []\n    \n    already_saved_images = False\n    \n    with torch.no_grad():\n        for i, (input_gray, input_ab, target) in enumerate(data_loader):\n            input_gray = input_gray.to(device) \n            input_ab = input_ab.to(device)\n            target = target.to(device)\n            \n            output_ab = model(input_gray) \n            loss = loss_func(output_ab, input_ab)\n            losses.append(loss.item())\n            \n            eval_predictions.append((output_ab,input_ab))\n            \n    return np.mean(losses),eval_predictions","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:04.081093Z","iopub.execute_input":"2021-12-17T11:31:04.081426Z","iopub.status.idle":"2021-12-17T11:31:04.096345Z","shell.execute_reply.started":"2021-12-17T11:31:04.081399Z","shell.execute_reply":"2021-12-17T11:31:04.095426Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Make folders and set parameters\nos.makedirs('checkpoints')\nbest_losses = 1e10","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:04.097556Z","iopub.execute_input":"2021-12-17T11:31:04.097789Z","iopub.status.idle":"2021-12-17T11:31:04.109873Z","shell.execute_reply.started":"2021-12-17T11:31:04.097762Z","shell.execute_reply":"2021-12-17T11:31:04.108916Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"epochs = 30","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:04.112508Z","iopub.execute_input":"2021-12-17T11:31:04.112736Z","iopub.status.idle":"2021-12-17T11:31:04.120471Z","shell.execute_reply.started":"2021-12-17T11:31:04.112709Z","shell.execute_reply":"2021-12-17T11:31:04.119620Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"history = {\"train_loss\":[], \"val_loss\":[]}\nleast_loss = 10000\n\nfor epoch in range(epochs):\n    print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n    print(\"-\"*100)\n    train_loss, epoch_time = train_epoch(model, train_loader, loss_func, optimizer, device)\n    print(\"Train Loss {:.4f}  Training Epoch Time {:.3f}s\".format(train_loss,epoch_time))\n    print()\n    \n    val_loss,val_predictions = eval_model(model, val_loader, loss_func, device)\n    print(\"Validation Loss {:.4f} \".format(val_loss))\n    print()\n    \n    history[\"train_loss\"].append(train_loss)\n    history[\"val_loss\"].append(val_loss)\n    \n    if val_loss < least_loss:\n        torch.save(model.state_dict(), \"best_model_state.bin\")\n        least_loss = val_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-17T11:31:04.121815Z","iopub.execute_input":"2021-12-17T11:31:04.122013Z","iopub.status.idle":"2021-12-17T16:28:51.070033Z","shell.execute_reply.started":"2021-12-17T11:31:04.121989Z","shell.execute_reply":"2021-12-17T16:28:51.067598Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print(\"\\n Final Test Loss :\\n\")\ntest_loss,test_predictions = eval_model(model, test_loader, loss_func, device)\nprint(test_loss)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:28:51.076216Z","iopub.execute_input":"2021-12-17T16:28:51.078125Z","iopub.status.idle":"2021-12-17T16:29:19.509914Z","shell.execute_reply.started":"2021-12-17T16:28:51.078052Z","shell.execute_reply":"2021-12-17T16:29:19.509021Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"plt.plot(history[\"train_loss\"], 'b')\nplt.plot(history[\"val_loss\"], 'r')\nplt.title('Train and Val losses over the epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:19.513338Z","iopub.execute_input":"2021-12-17T16:29:19.513667Z","iopub.status.idle":"2021-12-17T16:29:19.803793Z","shell.execute_reply.started":"2021-12-17T16:29:19.513634Z","shell.execute_reply":"2021-12-17T16:29:19.803120Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# To store the outputs\nos.makedirs('outputs/color', exist_ok=True)\nos.makedirs('outputs/gray', exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:19.804996Z","iopub.execute_input":"2021-12-17T16:29:19.805459Z","iopub.status.idle":"2021-12-17T16:29:19.810405Z","shell.execute_reply.started":"2021-12-17T16:29:19.805424Z","shell.execute_reply":"2021-12-17T16:29:19.809689Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def to_rgb(grayscale_input, ab_input, save_path=None, save_name=None):\n    plt.clf() # clear matplotlib \n    color_image = torch.cat((grayscale_input, ab_input), 0).numpy() # combine channels\n    color_image = color_image.transpose((1, 2, 0))  # rescale for matplotlib\n    color_image[:, :, 0:1] = color_image[:, :, 0:1] * 100\n    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128  \n    color_image = lab2rgb(color_image.astype(np.float64))\n    grayscale_input = grayscale_input.squeeze().numpy()\n    if save_path is not None and save_name is not None: \n        plt.imsave(arr=grayscale_input, fname='{}{}'.format(save_path['grayscale'], save_name), cmap='gray')\n        plt.imsave(arr=color_image, fname='{}{}'.format(save_path['colorized'], save_name))","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:19.811435Z","iopub.execute_input":"2021-12-17T16:29:19.811895Z","iopub.status.idle":"2021-12-17T16:29:19.822609Z","shell.execute_reply.started":"2021-12-17T16:29:19.811864Z","shell.execute_reply":"2021-12-17T16:29:19.821795Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_predictions[0][0].shape, test_predictions[0][1].shape, len(test_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:19.824159Z","iopub.execute_input":"2021-12-17T16:29:19.824663Z","iopub.status.idle":"2021-12-17T16:29:19.837710Z","shell.execute_reply.started":"2021-12-17T16:29:19.824608Z","shell.execute_reply":"2021-12-17T16:29:19.836861Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"save_path = {'grayscale': './outputs/gray/', 'colorized': './outputs/color/'}","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:19.839019Z","iopub.execute_input":"2021-12-17T16:29:19.839474Z","iopub.status.idle":"2021-12-17T16:29:19.848260Z","shell.execute_reply.started":"2021-12-17T16:29:19.839446Z","shell.execute_reply":"2021-12-17T16:29:19.847643Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"for i, (input_gray, input_ab, target) in enumerate(test_loader):\n    save_name = 'img-{}-batch-{}.jpg'.format(1, i)\n    to_rgb(input_gray[1].cpu(), ab_input= test_predictions[0][0][0].detach().cpu(), save_path=save_path, save_name=save_name)\n    if (i==10):\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:19.850268Z","iopub.execute_input":"2021-12-17T16:29:19.850844Z","iopub.status.idle":"2021-12-17T16:29:33.719562Z","shell.execute_reply.started":"2021-12-17T16:29:19.850805Z","shell.execute_reply":"2021-12-17T16:29:33.718643Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"color_images = os.listdir('./outputs/color')\ngrayscale_images = os.listdir('./outputs/gray')\nimage_tuples = list(zip(color_images, grayscale_images))","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:33.720749Z","iopub.execute_input":"2021-12-17T16:29:33.720938Z","iopub.status.idle":"2021-12-17T16:29:33.725598Z","shell.execute_reply.started":"2021-12-17T16:29:33.720914Z","shell.execute_reply":"2021-12-17T16:29:33.724860Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Show images\nfor c, g in image_tuples:\n    color = mpimg.imread('./outputs/color/'+c)\n    gray  = mpimg.imread('./outputs/gray/'+g)\n    f, axarr = plt.subplots(1, 2)\n    f.set_size_inches(15, 15)\n    axarr[0].imshow(gray, cmap='gray')\n    axarr[1].imshow(color)\n    axarr[0].axis('off'), axarr[1].axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:33.726947Z","iopub.execute_input":"2021-12-17T16:29:33.727410Z","iopub.status.idle":"2021-12-17T16:29:36.006317Z","shell.execute_reply.started":"2021-12-17T16:29:33.727369Z","shell.execute_reply":"2021-12-17T16:29:36.005738Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Show images\nfor c, g in image_tuples:\n    color = mpimg.imread('./outputs/color/'+c)\n    gray  = mpimg.imread('./outputs/gray/'+g)\n    f, axarr = plt.subplots(1, 2)\n    f.set_size_inches(15, 15)\n    axarr[0].imshow(gray, cmap='gray')\n    axarr[1].imshow(color)\n    axarr[0].axis('off'), axarr[1].axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-17T16:29:36.007494Z","iopub.execute_input":"2021-12-17T16:29:36.008096Z","iopub.status.idle":"2021-12-17T16:29:38.796500Z","shell.execute_reply.started":"2021-12-17T16:29:36.008065Z","shell.execute_reply":"2021-12-17T16:29:38.795653Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}